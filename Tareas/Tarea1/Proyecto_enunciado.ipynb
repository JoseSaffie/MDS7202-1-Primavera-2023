{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.dii.uchile.cl/wp-content/uploads/2021/06/Magi%CC%81ster-en-Ciencia-de-Datos.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Proyecto 1 - MDS7202 Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos üìö**\n",
    "\n",
    "**MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos**\n",
    "\n",
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesor: Ignacio Meza, Gabriel Iturra\n",
    "- Auxiliar: Sebasti√°n Tinoco\n",
    "- Ayudante: Arturo Lazcano, Angelo Mu√±oz\n",
    "\n",
    "*Por favor, lean detalladamente las instrucciones de la tarea antes de empezar a escribir.*\n",
    "\n",
    "### Equipo:\n",
    "\n",
    "- Nombre de alumno 1: Jose Ignacio Saffie\n",
    "- Nombre de alumno 2: Matias Lopez Roman\n",
    "\n",
    "\n",
    "### **Link de repositorio de GitHub:** `https://github.com/JoseSaffie/MDS7202-1-Primavera-2023.git`\n",
    "\n",
    "Fecha l√≠mite de entrega üìÜ: 27 de Octubre de 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Reglas\n",
    "\n",
    "- **Grupos de 2 personas.**\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Estrictamente prohibida la copia. \n",
    "- Pueden usar cualquier material del curso que estimen conveniente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://worldskateamerica.org/wp-content/uploads/2023/07/SANTIAGO-2023-1-768x153.jpg\" alt=\"Descripci√≥n de la imagen\">\n",
    "</div>\n",
    "\n",
    "En un Chile azotado por un profundo caos pol√≠tico-econ√≥mico y el resurgimiento de programas de televisi√≥n de dudosa calidad, todas las miradas y esperanzas son depositadas en el √©xito de un √∫nico evento: Santiago 2023. La naci√≥n necesitaba desesperadamente un respiro, y los Juegos de Santiago 2023 promet√≠an ser una luz al final del t√∫nel.\n",
    "\n",
    "El Presidente de la Rep√∫blica -conocido en las calles como Bomb√≠n-, consciente de la importancia de este evento para la revitalizaci√≥n del pa√≠s, decide convocar a usted y su equipo en calidad de expertos en an√°lisis de datos y estad√≠sticas. Con gran solemnidad, el presidente les encomienda una importante y peligrosa: liderar un proyecto que permitiera caracterizar de forma autom√°tica y eficiente los datos generados por estos magnos juegos. Para esto, el presidente le destaca que la soluci√≥n debe considerar los siguientes puntos:\n",
    "- Caracterizaci√≥n autom√°tica de los datos\n",
    "- La soluci√≥n debe ser compatible con cualquier dataset\n",
    "- Se les facilita el dataset *olimpiadas.parquet*, el cual recopila data de diferentes juegos ol√≠mpicos realizados en los √∫ltimos a√±os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Creaci√≥n de `Profiler` Class (4.0 puntos)\n",
    "\n",
    "Cree la clase `Profiler`. Como m√≠nimo, esta debe tener las siguientes funcionalidades:\n",
    "\n",
    "1. El m√©todo constructor, el cual debe recibir los datos a procesar en formato `Pandas DataFrame`. Adem√°s, este m√©todo debe generar una carpeta en su directorio de trabajo con el nombre `EDA_fecha`, donde `fecha` corresponda a la fecha de ejecuci√≥n en formato `DD-MM-YYYY`.\n",
    "\n",
    "2. El m√©todo `summarize`, el cual debe caracterizar las variables del Dataset. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Reportar el tipo de variable\n",
    "    - Reportar el n√∫mero y/o porcentaje de valores √∫nicos de la variable\n",
    "    - Reportar el n√∫mero y/o porcentaje de valores nulos\n",
    "    - Si la variables es num√©rica:\n",
    "        - Reportar el n√∫mero y/o porcentaje de valores cero, negativos y outliers\n",
    "        - Reportar estad√≠stica descriptiva como el valor m√≠nimo, m√°ximo, promedio y los percentiles 25, 50, 75 y 100\n",
    "   - Levantar una alerta en caso de encontrar alguna anomal√≠a fuera de lo com√∫n (el criterio debe ser ajustable por el usuario)\n",
    "   - Guardar sus resultados en el directorio `EDA_fecha/summary.txt`. El archivo debe separar de forma clara y ordenada los resultados de cada punto.\n",
    "\n",
    "3. El m√©todo `plot_vars`, el cual debe graficar la distribuci√≥n e interraciones de las variables del Dataset. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/plots`\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Para las variables num√©ricas:\n",
    "        - Genere un gr√°fico de distribuci√≥n de densidad\n",
    "        - Grafique la correlaci√≥n entre las variables\n",
    "    - Para las variables categ√≥ricas:\n",
    "        - Genere un histograma de las top N categor√≠as (N debe ser un par√°metro ajustable)\n",
    "        - Grafique el coeficiente V de Cramer entre las variables\n",
    "    - Guardar cada gr√°fico generado en la carpeta `EDA_fecha/plots` en formato `.pdf` y bajo el naming `variable.pdf`, donde `variable` es el nombre de la variable de inter√©s\n",
    "    \n",
    "4. El m√©todo `clean_data`, el cual debe limpiar los datos para que luego puedan ser procesados. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/clean_data`\n",
    "    - Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    - Drop de valores duplicados\n",
    "    - Implementar como m√≠nimo 2 t√©cnicas para tratar los valores nulos, como:\n",
    "        - Drop de valores nulos\n",
    "        - Imputar valores nulos con alguna t√©cnica de imputaci√≥n\n",
    "        - Funcionalidad para escoger entre una t√©cnica y la otra.\n",
    "    - Una de las columnas del dataframe presenta datos *no at√≥micos*. Separe dicha columna en las columnas que la compongan.\n",
    "        - Hint: ¬øQu√© caracteres permiten separar una columna de otra?\n",
    "        - Para las pruebas con el dataset nuevo, puede esperar que exista al menos una columna con este tipo de problema. Asuma que los separadores ser√°n los mismos, aunque el n√∫mero de columnas a separar puede ser distinto.\n",
    "    - Deber√≠an usar `FunctionTransformer`.\n",
    "    - Guardar los datos procesados en formato `.csv` en el path `EDA_fecha/clean_data/data.csv`\n",
    "\n",
    "5. El m√©todo `scale`, el cual debe preparar adecuadamente los datos para luego ser consumidos por alg√∫n tipo de algoritmo. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/scale`\n",
    "    - Procesar de forma adecuada los datos num√©ricos y categ√≥ricos:\n",
    "        - Su m√©todo debe recibir las t√©cnicas de escalamiento como argumento de entrada (utilizar solo t√©cnicas compatibles con el framework de `sklearn`)\n",
    "        - Para los atributos num√©ricos, se transforme los datos con un escalador logar√≠tmico y un `MinMaxScaler`\n",
    "        - Asuma que no existen datos ordinales en su dataset\n",
    "    - Guardar todo este procesamiento en un `ColumnTransformer`.\n",
    "    - Guardar los datos limpios y transformados en formato `.csv` en el path `EDA_fecha/process/scaled_features.csv`\n",
    "\n",
    "6. El m√©todo `make_clusters`, el cual debe generar clusters de los datos usando alg√∫n algoritmo de clusterizaci√≥n. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    - Crear la carpeta `EDA_fecha/clusters`\n",
    "    - Generar un estudio del codo donde se√±ale la cantidad de clusters optimos para el desarrollo.\n",
    "    - Su m√©todo debe recibir el algoritmo de clustering como argumento de entrada (utilizar solo algoritmos compatibles con el framework de `sklearn`).\n",
    "    - No olvide pre procesar adecuadamente los datos antes de implementar la t√©cnica de clustering. \n",
    "    - En este punto es espera que generen un `Pipeline` de sklearn. Adem√°s, su m√©todo deber√≠a usar lo construido en los puntos 4 y 5. \n",
    "    - Su m√©todo debe ser capaz de funcionar a partir de datos crudos (se descontar√° puntaje de lo contrario).\n",
    "    - Una vez generado los clusters, proyecte los datos a 2 dimensiones usando su t√©cnica de reducci√≥n de dimensionalidad favorita y grafique los resultados coloreando por cluster.\n",
    "    - Guardar los datos con su respectivo cluster en formato `.csv` en el path `EDA_fecha/clusters/data_clusters.csv`. Guarde tambi√©n los gr√°ficos generados en el mismo path.\n",
    "\n",
    "7. El m√©todo `detect_anomalies`, el cual debe detectar anomal√≠as en los datos. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "\n",
    "    - Crear la carpeta `EDA_fecha/anomalies`\n",
    "    - Implementar alguna t√©cnica de detecci√≥n de anomal√≠as.\n",
    "    - Al igual que el punto anterior, su m√©todo debe considerar los siguientes puntos:\n",
    "        - No olvide pre procesar de forma adecuada los datos antes de implementar la t√©cnica de detecci√≥n de anomal√≠a. \n",
    "        - En este punto es espera que generen un `Pipeline` de sklearn. Adem√°s, su m√©todo deber√≠a usar lo construido en los puntos 4 y 5. \n",
    "        - Su m√©todo debe ser capaz de funcionar a partir de datos crudos (se descontar√° puntaje de lo contrario).\n",
    "        - Su m√©todo debe recibir el algoritmo como argumento de entrada\n",
    "        - Una vez generado las etiquetas, proyecte los datos a 2 dimensiones y grafique los resultados coloreando por las etiquetas predichas por el detector de anomal√≠as\n",
    "    - Guardar los datos con su respectiva etiqueta en formato `.csv` en el path `EDA_fecha/anomalies/data_anomalies.csv`. Guarde tambi√©n los gr√°ficos generados en el mismo path.\n",
    "\n",
    "8. El m√©todo `profile`, el cual debe ejecutar todos los m√©todos anteriores.\n",
    "\n",
    "9. Crear el m√©todo `clearGarbage` para eliminar las carpetas/archivos creados/as por la clase `Profiler`.\n",
    "\n",
    "Algunas consideraciones generales:\n",
    "- Su clase ser√° testeada con datos tabulares diferentes a los provistos. No desarrollen c√≥digo *hardcodeado*: su clase debe ser capaz de funcionar para **cualquier** dataset. \n",
    "- Aplique todo su conocimiento sobre buenas pr√°cticas de programaci√≥n: se evaluar√° que su c√≥digo sea limpio y ordenado.\n",
    "- Recuerden documentar cada una de las funcionalidades que implementen.\n",
    "- Recuerden adjuntar sus `requirements.txt` junto a su entrega de proyecto. **El c√≥digo que no se pueda ejecutar por imcompatibilidades de librer√≠as no ser√° corregido.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting associations\n",
      "  Downloading associations-0.0.4-py3-none-any.whl (3.6 kB)\n",
      "Installing collected packages: associations\n",
      "Successfully installed associations-0.0.4\n"
     ]
    }
   ],
   "source": [
    "### Librerias importantes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import date\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2_contingency\n",
    "from associations import cramers_v\n",
    "\n",
    "#\n",
    "#!pip install pyarrow\n",
    "#!pip install fastparquet\n",
    "#!pip install associations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cargar datos\n",
    "df = pd.read_parquet('olimpiadas.parquet')\n",
    "arreglorap = np.array([1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Profiler():\n",
    "\n",
    "    # 1. El m√©todo constructor, el cual debe recibir los datos a procesar en formato `Pandas DataFrame`.\n",
    "    #  Adem√°s, este m√©todo debe generar una carpeta en su directorio de trabajo con el nombre `EDA_fecha`,\n",
    "    #  donde `fecha` corresponda a la fecha de ejecuci√≥n en formato `DD-MM-YYYY`.\n",
    "\n",
    "    def __init__(self, dataframe_in):\n",
    "\n",
    "        # Nos aseguramos que sea una dataframe de pandas para crear la carpeta\n",
    "        if isinstance(dataframe_in, pd.DataFrame):\n",
    "\n",
    "            self.dataframe = dataframe_in\n",
    "            # Obtenemos los datos de hoy y agregamos la parte de 'EDA' para tener el str completo\n",
    "            now = date.today()\n",
    "            self.carpeta_nombre = 'EDA_' + now.strftime(\"%d-%m-%Y\")\n",
    "\n",
    "\n",
    "            # Creamos un condicional para crear la carpeta solo cuando existe\n",
    "            if not os.path.exists(self.carpeta_nombre):\n",
    "                os.mkdir(self.carpeta_nombre)\n",
    "                print(f'Se ha creado la carpeta: {self.carpeta_nombre}')\n",
    "\n",
    "            # Si no printear un error donde la carpeta ya existe    \n",
    "            else:\n",
    "                raise TypeError(\n",
    "                \"Ya se creo una carpeta con este nombre, por favor eliminar la carpeta\"\n",
    "            )  \n",
    "                     \n",
    "        # Si no, tirar error\n",
    "        else:\n",
    "            raise TypeError(\n",
    "                \"Debes ingresar datos en formato de Pandas DataFrame\"\n",
    "            )        \n",
    "        \n",
    "    \n",
    "    #2. El m√©todo `summarize`, el cual debe caracterizar las variables del Dataset. Como m√≠nimo, se espera que su m√©todo pueda:\n",
    "    #- Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s. (listo)\n",
    "    #- Reportar el tipo de variable (ok)\n",
    "    #- Reportar el n√∫mero y/o porcentaje de valores √∫nicos de la variable (OK)\n",
    "    #- Reportar el n√∫mero y/o porcentaje de valores nulos (OK)\n",
    "    #- Si la variables es num√©rica:\n",
    "    #    - Reportar el n√∫mero y/o porcentaje de valores cero, negativos y outliers\n",
    "    #    - Reportar estad√≠stica descriptiva como el valor m√≠nimo, m√°ximo, promedio y los percentiles 25, 50, 75 y 100\n",
    "    # - Levantar una alerta en caso de encontrar alguna anomal√≠a fuera de lo com√∫n (el criterio debe ser ajustable por el usuario)\n",
    "    #- Guardar sus resultados en el directorio `EDA_fecha/summary.txt`. El archivo debe separar de forma clara y ordenada los resultados de cada punto.\n",
    "    \n",
    "    def summarize(self,anomalia = 25, variables=None):\n",
    "\n",
    "        def calcular_outliers(columna):\n",
    "            Q1 = columna.quantile(0.25)\n",
    "            Q3 = columna.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            inferior = Q1 - 1.5 * IQR\n",
    "            superior = Q3 + 1.5 * IQR\n",
    "            outliers = (columna < inferior) | (columna > superior)\n",
    "            return outliers.sum()\n",
    "\n",
    "        ruta = os.path.join(self.carpeta_nombre, 'summary.txt')\n",
    "        with open(ruta, 'w') as archivo_summary:\n",
    "            for column in self.dataframe.columns:\n",
    "                if variables and column not in variables:\n",
    "                    continue  # Salta la columna si no est√° en la lista de inter√©s\n",
    "                variable_summary = {}\n",
    "                variable_summary['Variable'] = column\n",
    "                variable_summary['Tipo'] = str(self.dataframe[column].dtype)\n",
    "                variable_summary['Valores Unicos'] = self.dataframe[column].nunique()\n",
    "                variable_summary['Valores Nulos'] = self.dataframe[column].isnull().sum()\n",
    "                variable_summary['Porcentaje Nulos'] = (variable_summary['Valores Nulos'] / len(self.dataframe)) * 100\n",
    "\n",
    "                if self.dataframe[column].dtype in ['int64', 'float64']:\n",
    "                    variable_summary['Valores Cero'] = (self.dataframe[column] == 0).sum()\n",
    "                    variable_summary['Valores Negativos'] = (self.dataframe[column] < 0).sum()\n",
    "                    variable_summary['Valores Outliers'] = calcular_outliers(self.dataframe[column])\n",
    "                    variable_summary['Minimo'] = self.dataframe[column].min()\n",
    "                    variable_summary['Maximo'] = self.dataframe[column].max()\n",
    "                    variable_summary['Promedio'] = self.dataframe[column].mean()\n",
    "                    variable_summary['Percentil 25'] = self.dataframe[column].quantile(0.25)\n",
    "                    variable_summary['Percentil 50'] = self.dataframe[column].median()\n",
    "                    variable_summary['Percentil 75'] = self.dataframe[column].quantile(0.75)\n",
    "\n",
    "                # Alerta por anomal√≠a (por ejemplo, m√°s del 10% de valores nulos)\n",
    "                if variable_summary['Porcentaje Nulos'] > anomalia:\n",
    "                    archivo_summary.write(f\"Alerta: La variable '{variable_summary['Variable']}' tiene mas del {anomalia}% de valores nulos.\\n\")\n",
    "\n",
    "            \n",
    "                # Escribir el resumen en el archivo\n",
    "                archivo_summary.write(f\"Variable: {variable_summary['Variable']}\\n\")\n",
    "                archivo_summary.write(f\"Tipo: {variable_summary['Tipo']}\\n\")\n",
    "                archivo_summary.write(f\"Valores Unicos: {variable_summary['Valores Unicos']}\\n\")\n",
    "                archivo_summary.write(f\"Valores Nulos: {variable_summary['Valores Nulos']}\\n\")\n",
    "                archivo_summary.write(f\"Porcentaje Nulos: {variable_summary['Porcentaje Nulos']:.2f}%\\n\")\n",
    "                # Escribir m√°s estad√≠sticas si es necesario\n",
    "                archivo_summary.write(f\"Valores Cero: {variable_summary.get('Valores Cero', 0)}\\n\")\n",
    "                archivo_summary.write(f\"Valores Negativos: {variable_summary.get('Valores Negativos', 0)}\\n\")\n",
    "                archivo_summary.write(f\"Valores Outliers: {variable_summary.get('Valores Outliers', 0)}\\n\")\n",
    "                archivo_summary.write(f\"Minimo: {variable_summary.get('Minimo', 0)}\\n\")\n",
    "                archivo_summary.write(f\"Maximo: {variable_summary.get('Maximo', 0)}\\n\")\n",
    "                archivo_summary.write(f\"Promedio: {variable_summary.get('Promedio', 0)}\\n\")\n",
    "                archivo_summary.write(f\"Percentil 25: {variable_summary.get('Percentil 25', 0)}\\n\")\n",
    "                archivo_summary.write(f\"Percentil 50: {variable_summary.get('Percentil 50', 0)}\\n\")\n",
    "                archivo_summary.write(f\"Percentil 75: {variable_summary.get('Percentil 75', 0)}\\n\")\n",
    "                # L√≠nea separadora\n",
    "                archivo_summary.write(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "        print(f\"Resumen de variables guardado en {ruta}\")\n",
    "\n",
    "# El m√©todo `plot_vars`, el cual debe graficar la distribuci√≥n e interraciones de las variables del Dataset. Como m√≠nimo, se espera que su m√©todo pueda:#\n",
    "    #- Crear la carpeta `EDA_fecha/plots`\n",
    "    #- Implementar una funcionalidad para filtrar y aplicar este m√©todo a una o m√°s variables de inter√©s.\n",
    "    #- Para las variables num√©ricas:\n",
    "    #    - Genere un gr√°fico de distribuci√≥n de densidad\n",
    "    #    - Grafique la correlaci√≥n entre las variables\n",
    "    #- Para las variables categ√≥ricas:\n",
    "    #    - Genere un histograma de las top N categor√≠as (N debe ser un par√°metro ajustable)\n",
    "    #    - Grafique el coeficiente V de Cramer entre las variables\n",
    "    #- Guardar cada gr√°fico generado en la carpeta `EDA_fecha/plots` en formato `.pdf` y bajo el naming `variable.pdf`, donde `variable` es el nombre de la variable de inter√©s\n",
    "            \n",
    "\n",
    "\n",
    "    def plot_vars(self, variables=None, top_categorias=5):\n",
    "        # Crea la carpeta para los gr√°ficos si no existe\n",
    "        carpeta_plots = os.path.join(self.carpeta_nombre, 'plots')\n",
    "        if not os.path.exists(carpeta_plots):\n",
    "            os.mkdir(carpeta_plots)\n",
    "\n",
    "        # Filtra las variables si se proporcionan\n",
    "        if variables:\n",
    "            variables = [var for var in variables if var in self.dataframe.columns]\n",
    "        else:\n",
    "            variables = self.dataframe.columns\n",
    "\n",
    "        for var in variables:\n",
    "            if var in self.dataframe.select_dtypes(include=['int64', 'float64']).columns:\n",
    "                # Gr√°fico de distribuci√≥n de densidad para variables num√©ricas\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.histplot(self.dataframe[var], kde=True)\n",
    "                plt.xlabel(var)\n",
    "                plt.ylabel('Densidad')\n",
    "                plt.title(f'Distribuci√≥n de {var}')\n",
    "                plt.savefig(os.path.join(carpeta_plots, f'{var}.pdf'))\n",
    "                plt.close()\n",
    "\n",
    "                # Graficar la correlaci√≥n entre las variables num√©ricas\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.heatmap(self.dataframe.corr(), annot=True, cmap='coolwarm')\n",
    "                plt.title('Correlaci√≥n entre variables num√©ricas')\n",
    "                plt.savefig(os.path.join(carpeta_plots, 'correlation_matrix.pdf'))\n",
    "                plt.close()\n",
    "\n",
    "            elif var in self.dataframe.select_dtypes(include=['object']).columns:\n",
    "                # Histograma de las top N categor√≠as para variables categ√≥ricas\n",
    "                categorias_top = self.dataframe[var].value_counts().head(top_categorias)\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.barplot(x=categorias_top.index, y=categorias_top.values)\n",
    "                plt.xlabel(var)\n",
    "                plt.ylabel('Frecuencia')\n",
    "                plt.title(f'Principales {top_categorias} categor√≠as de {var}')\n",
    "                plt.savefig(os.path.join(carpeta_plots, f'{var}_categorias_top.pdf'))\n",
    "                plt.close()\n",
    "\n",
    "                # C√°lculo del coeficiente V de Cramer\n",
    "                contingency_table = pd.crosstab(self.dataframe[var], self.dataframe[var])\n",
    "                _, _, _, expected = chi2_contingency(contingency_table)\n",
    "                chi2 = chi2_contingency(contingency_table)[0]\n",
    "                n = contingency_table.sum().sum()\n",
    "                phi2 = chi2 / n\n",
    "                r, k = contingency_table.shape\n",
    "                phi2corr = max(0, phi2 - ((k - 1) * (r - 1)) / (n - 1))\n",
    "                rcorr = r - ((r - 1) ** 2) / (n - 1)\n",
    "                kcorr = k - ((k - 1) ** 2) / (n - 1)\n",
    "                cramers_v = np.sqrt(phi2corr / min((kcorr - 1), (rcorr - 1)))\n",
    "                plt.figure(figsize=(6, 4))\n",
    "                sns.barplot(x=[var], y=[cramers_v])\n",
    "                plt.ylabel('Coeficiente V de Cramer')\n",
    "                plt.title(f'Coeficiente V de Cramer para {var}')\n",
    "                plt.savefig(os.path.join(carpeta_plots, f'{var}_cramers_v.pdf'))\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Team</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Games</th>\n",
       "      <th>Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>City</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Event</th>\n",
       "      <th>Medal</th>\n",
       "      <th>age-height-weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A Dijiang</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>1992 Summer</td>\n",
       "      <td>1992</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Basketball</td>\n",
       "      <td>Basketball Men's Basketball</td>\n",
       "      <td>None</td>\n",
       "      <td>24.0*180.0?80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A Lamusi</td>\n",
       "      <td>M</td>\n",
       "      <td>China</td>\n",
       "      <td>CHN</td>\n",
       "      <td>2012 Summer</td>\n",
       "      <td>2012</td>\n",
       "      <td>Summer</td>\n",
       "      <td>London</td>\n",
       "      <td>Judo</td>\n",
       "      <td>Judo Men's Extra-Lightweight</td>\n",
       "      <td>None</td>\n",
       "      <td>23.0(170.0?60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Gunnar Nielsen Aaby</td>\n",
       "      <td>M</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1920 Summer</td>\n",
       "      <td>1920</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Antwerpen</td>\n",
       "      <td>Football</td>\n",
       "      <td>Football Men's Football</td>\n",
       "      <td>None</td>\n",
       "      <td>24.0(nan?nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Edgar Lindenau Aabye</td>\n",
       "      <td>M</td>\n",
       "      <td>Denmark/Sweden</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1900 Summer</td>\n",
       "      <td>1900</td>\n",
       "      <td>Summer</td>\n",
       "      <td>Paris</td>\n",
       "      <td>Tug-Of-War</td>\n",
       "      <td>Tug-Of-War Men's Tug-Of-War</td>\n",
       "      <td>Gold</td>\n",
       "      <td>34.0:nan?nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Christine Jacoba Aaftink</td>\n",
       "      <td>F</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>NED</td>\n",
       "      <td>1988 Winter</td>\n",
       "      <td>1988</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Calgary</td>\n",
       "      <td>Speed Skating</td>\n",
       "      <td>Speed Skating Women's 500 metres</td>\n",
       "      <td>None</td>\n",
       "      <td>21.0(185.0?82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271111</th>\n",
       "      <td>135569</td>\n",
       "      <td>Andrzej ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland-1</td>\n",
       "      <td>POL</td>\n",
       "      <td>1976 Winter</td>\n",
       "      <td>1976</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Innsbruck</td>\n",
       "      <td>Luge</td>\n",
       "      <td>Luge Mixed (Men)'s Doubles</td>\n",
       "      <td>None</td>\n",
       "      <td>29.0:179.0?89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271112</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Individual</td>\n",
       "      <td>None</td>\n",
       "      <td>27.0:176.0?59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271113</th>\n",
       "      <td>135570</td>\n",
       "      <td>Piotr ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2014 Winter</td>\n",
       "      <td>2014</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Sochi</td>\n",
       "      <td>Ski Jumping</td>\n",
       "      <td>Ski Jumping Men's Large Hill, Team</td>\n",
       "      <td>None</td>\n",
       "      <td>27.0*176.0?59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271114</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>1998 Winter</td>\n",
       "      <td>1998</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Nagano</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>None</td>\n",
       "      <td>30.0(185.0?96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271115</th>\n",
       "      <td>135571</td>\n",
       "      <td>Tomasz Ireneusz ya</td>\n",
       "      <td>M</td>\n",
       "      <td>Poland</td>\n",
       "      <td>POL</td>\n",
       "      <td>2002 Winter</td>\n",
       "      <td>2002</td>\n",
       "      <td>Winter</td>\n",
       "      <td>Salt Lake City</td>\n",
       "      <td>Bobsleigh</td>\n",
       "      <td>Bobsleigh Men's Four</td>\n",
       "      <td>None</td>\n",
       "      <td>34.0(185.0?96.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>271116 rows √ó 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ID                      Name Sex            Team  NOC  \\\n",
       "0            1                 A Dijiang   M           China  CHN   \n",
       "1            2                  A Lamusi   M           China  CHN   \n",
       "2            3       Gunnar Nielsen Aaby   M         Denmark  DEN   \n",
       "3            4      Edgar Lindenau Aabye   M  Denmark/Sweden  DEN   \n",
       "4            5  Christine Jacoba Aaftink   F     Netherlands  NED   \n",
       "...        ...                       ...  ..             ...  ...   \n",
       "271111  135569                Andrzej ya   M        Poland-1  POL   \n",
       "271112  135570                  Piotr ya   M          Poland  POL   \n",
       "271113  135570                  Piotr ya   M          Poland  POL   \n",
       "271114  135571        Tomasz Ireneusz ya   M          Poland  POL   \n",
       "271115  135571        Tomasz Ireneusz ya   M          Poland  POL   \n",
       "\n",
       "              Games  Year  Season            City          Sport  \\\n",
       "0       1992 Summer  1992  Summer       Barcelona     Basketball   \n",
       "1       2012 Summer  2012  Summer          London           Judo   \n",
       "2       1920 Summer  1920  Summer       Antwerpen       Football   \n",
       "3       1900 Summer  1900  Summer           Paris     Tug-Of-War   \n",
       "4       1988 Winter  1988  Winter         Calgary  Speed Skating   \n",
       "...             ...   ...     ...             ...            ...   \n",
       "271111  1976 Winter  1976  Winter       Innsbruck           Luge   \n",
       "271112  2014 Winter  2014  Winter           Sochi    Ski Jumping   \n",
       "271113  2014 Winter  2014  Winter           Sochi    Ski Jumping   \n",
       "271114  1998 Winter  1998  Winter          Nagano      Bobsleigh   \n",
       "271115  2002 Winter  2002  Winter  Salt Lake City      Bobsleigh   \n",
       "\n",
       "                                           Event Medal age-height-weight  \n",
       "0                    Basketball Men's Basketball  None   24.0*180.0?80.0  \n",
       "1                   Judo Men's Extra-Lightweight  None   23.0(170.0?60.0  \n",
       "2                        Football Men's Football  None      24.0(nan?nan  \n",
       "3                    Tug-Of-War Men's Tug-Of-War  Gold      34.0:nan?nan  \n",
       "4               Speed Skating Women's 500 metres  None   21.0(185.0?82.0  \n",
       "...                                          ...   ...               ...  \n",
       "271111                Luge Mixed (Men)'s Doubles  None   29.0:179.0?89.0  \n",
       "271112  Ski Jumping Men's Large Hill, Individual  None   27.0:176.0?59.0  \n",
       "271113        Ski Jumping Men's Large Hill, Team  None   27.0*176.0?59.0  \n",
       "271114                      Bobsleigh Men's Four  None   30.0(185.0?96.0  \n",
       "271115                      Bobsleigh Men's Four  None   34.0(185.0?96.0  \n",
       "\n",
       "[271116 rows x 13 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha creado la carpeta: EDA_05-11-2023\n"
     ]
    }
   ],
   "source": [
    "dataset = Profiler(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de variables guardado en EDA_05-11-2023\\summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Analizar todas las variables del DataFrame\n",
    "dataset.summarize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumen de variables guardado en EDA_05-11-2023\\summary.txt\n"
     ]
    }
   ],
   "source": [
    "# Analizar solo las variables 'variable1' y 'variable2'\n",
    "dataset.summarize(variables=['Season', 'Medal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GE62VR 6RF\\AppData\\Local\\Temp\\ipykernel_18008\\2720643939.py:145: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  sns.heatmap(self.dataframe.corr(), annot=True, cmap='coolwarm')\n",
      "d:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\reshape.py:126: RuntimeWarning: overflow encountered in scalar multiply\n",
      "  num_cells = num_rows * num_columns\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 972906993 is out of bounds for axis 0 with size 972842640",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\Tareas\\Tarea1\\Proyecto_enunciado.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Universidad/Laboratorio%20de%20Programacion/MDS7202-1-Primavera-2023/Tareas/Tarea1/Proyecto_enunciado.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dataset\u001b[39m.\u001b[39;49mplot_vars()\n",
      "\u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\Tareas\\Tarea1\\Proyecto_enunciado.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Universidad/Laboratorio%20de%20Programacion/MDS7202-1-Primavera-2023/Tareas/Tarea1/Proyecto_enunciado.ipynb#X23sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m plt\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Universidad/Laboratorio%20de%20Programacion/MDS7202-1-Primavera-2023/Tareas/Tarea1/Proyecto_enunciado.ipynb#X23sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m \u001b[39m# C√°lculo del coeficiente V de Cramer\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/Universidad/Laboratorio%20de%20Programacion/MDS7202-1-Primavera-2023/Tareas/Tarea1/Proyecto_enunciado.ipynb#X23sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m contingency_table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mcrosstab(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataframe[var], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataframe[var])\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Universidad/Laboratorio%20de%20Programacion/MDS7202-1-Primavera-2023/Tareas/Tarea1/Proyecto_enunciado.ipynb#X23sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m _, _, _, expected \u001b[39m=\u001b[39m chi2_contingency(contingency_table)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/Universidad/Laboratorio%20de%20Programacion/MDS7202-1-Primavera-2023/Tareas/Tarea1/Proyecto_enunciado.ipynb#X23sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m chi2 \u001b[39m=\u001b[39m chi2_contingency(contingency_table)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:691\u001b[0m, in \u001b[0;36mcrosstab\u001b[1;34m(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\u001b[0m\n\u001b[0;32m    688\u001b[0m     df[\u001b[39m\"\u001b[39m\u001b[39m__dummy__\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m values\n\u001b[0;32m    689\u001b[0m     kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39maggfunc\u001b[39m\u001b[39m\"\u001b[39m: aggfunc}\n\u001b[1;32m--> 691\u001b[0m table \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39;49mpivot_table(\n\u001b[0;32m    692\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m__dummy__\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    693\u001b[0m     index\u001b[39m=\u001b[39;49munique_rownames,\n\u001b[0;32m    694\u001b[0m     columns\u001b[39m=\u001b[39;49munique_colnames,\n\u001b[0;32m    695\u001b[0m     margins\u001b[39m=\u001b[39;49mmargins,\n\u001b[0;32m    696\u001b[0m     margins_name\u001b[39m=\u001b[39;49mmargins_name,\n\u001b[0;32m    697\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m    698\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[0;32m    699\u001b[0m )\n\u001b[0;32m    701\u001b[0m \u001b[39m# Post-process\u001b[39;00m\n\u001b[0;32m    702\u001b[0m \u001b[39mif\u001b[39;00m normalize \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:8731\u001b[0m, in \u001b[0;36mDataFrame.pivot_table\u001b[1;34m(self, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m   8714\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   8715\u001b[0m \u001b[39m@Appender\u001b[39m(_shared_docs[\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m   8716\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpivot_table\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   8727\u001b[0m     sort\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m   8728\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m   8729\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpivot\u001b[39;00m \u001b[39mimport\u001b[39;00m pivot_table\n\u001b[1;32m-> 8731\u001b[0m     \u001b[39mreturn\u001b[39;00m pivot_table(\n\u001b[0;32m   8732\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   8733\u001b[0m         values\u001b[39m=\u001b[39;49mvalues,\n\u001b[0;32m   8734\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[0;32m   8735\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[0;32m   8736\u001b[0m         aggfunc\u001b[39m=\u001b[39;49maggfunc,\n\u001b[0;32m   8737\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[0;32m   8738\u001b[0m         margins\u001b[39m=\u001b[39;49mmargins,\n\u001b[0;32m   8739\u001b[0m         dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   8740\u001b[0m         margins_name\u001b[39m=\u001b[39;49mmargins_name,\n\u001b[0;32m   8741\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   8742\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   8743\u001b[0m     )\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:97\u001b[0m, in \u001b[0;36mpivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m     94\u001b[0m     table \u001b[39m=\u001b[39m concat(pieces, keys\u001b[39m=\u001b[39mkeys, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 97\u001b[0m table \u001b[39m=\u001b[39m __internal_pivot_table(\n\u001b[0;32m     98\u001b[0m     data,\n\u001b[0;32m     99\u001b[0m     values,\n\u001b[0;32m    100\u001b[0m     index,\n\u001b[0;32m    101\u001b[0m     columns,\n\u001b[0;32m    102\u001b[0m     aggfunc,\n\u001b[0;32m    103\u001b[0m     fill_value,\n\u001b[0;32m    104\u001b[0m     margins,\n\u001b[0;32m    105\u001b[0m     dropna,\n\u001b[0;32m    106\u001b[0m     margins_name,\n\u001b[0;32m    107\u001b[0m     observed,\n\u001b[0;32m    108\u001b[0m     sort,\n\u001b[0;32m    109\u001b[0m )\n\u001b[0;32m    110\u001b[0m \u001b[39mreturn\u001b[39;00m table\u001b[39m.\u001b[39m__finalize__(data, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpivot_table\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\pivot.py:219\u001b[0m, in \u001b[0;36m__internal_pivot_table\u001b[1;34m(data, values, index, columns, aggfunc, fill_value, margins, dropna, margins_name, observed, sort)\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    218\u001b[0m             to_unstack\u001b[39m.\u001b[39mappend(name)\n\u001b[1;32m--> 219\u001b[0m     table \u001b[39m=\u001b[39m agged\u001b[39m.\u001b[39;49munstack(to_unstack)\n\u001b[0;32m    221\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m dropna:\n\u001b[0;32m    222\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(table\u001b[39m.\u001b[39mindex, MultiIndex):\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:9112\u001b[0m, in \u001b[0;36mDataFrame.unstack\u001b[1;34m(self, level, fill_value)\u001b[0m\n\u001b[0;32m   9050\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9051\u001b[0m \u001b[39mPivot a level of the (necessarily hierarchical) index labels.\u001b[39;00m\n\u001b[0;32m   9052\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9108\u001b[0m \u001b[39mdtype: float64\u001b[39;00m\n\u001b[0;32m   9109\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   9110\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m \u001b[39mimport\u001b[39;00m unstack\n\u001b[1;32m-> 9112\u001b[0m result \u001b[39m=\u001b[39m unstack(\u001b[39mself\u001b[39;49m, level, fill_value)\n\u001b[0;32m   9114\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munstack\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\reshape.py:476\u001b[0m, in \u001b[0;36munstack\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, DataFrame):\n\u001b[0;32m    475\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m--> 476\u001b[0m         \u001b[39mreturn\u001b[39;00m _unstack_frame(obj, level, fill_value\u001b[39m=\u001b[39;49mfill_value)\n\u001b[0;32m    477\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mT\u001b[39m.\u001b[39mstack(dropna\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\reshape.py:499\u001b[0m, in \u001b[0;36m_unstack_frame\u001b[1;34m(obj, level, fill_value)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unstack_frame\u001b[39m(obj: DataFrame, level, fill_value\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(obj\u001b[39m.\u001b[39mindex, MultiIndex)  \u001b[39m# checked by caller\u001b[39;00m\n\u001b[1;32m--> 499\u001b[0m     unstacker \u001b[39m=\u001b[39m _Unstacker(obj\u001b[39m.\u001b[39;49mindex, level\u001b[39m=\u001b[39;49mlevel, constructor\u001b[39m=\u001b[39;49mobj\u001b[39m.\u001b[39;49m_constructor)\n\u001b[0;32m    501\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m obj\u001b[39m.\u001b[39m_can_fast_transpose:\n\u001b[0;32m    502\u001b[0m         mgr \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39munstack(unstacker, fill_value\u001b[39m=\u001b[39mfill_value)\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\reshape.py:137\u001b[0m, in \u001b[0;36m_Unstacker.__init__\u001b[1;34m(self, index, level, constructor)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m num_cells \u001b[39m>\u001b[39m np\u001b[39m.\u001b[39miinfo(np\u001b[39m.\u001b[39mint32)\u001b[39m.\u001b[39mmax:\n\u001b[0;32m    130\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    131\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe following operation may generate \u001b[39m\u001b[39m{\u001b[39;00mnum_cells\u001b[39m}\u001b[39;00m\u001b[39m cells \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    132\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39min the resulting pandas object.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    133\u001b[0m         PerformanceWarning,\n\u001b[0;32m    134\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    135\u001b[0m     )\n\u001b[1;32m--> 137\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_selectors()\n",
      "File \u001b[1;32md:\\Universidad\\Laboratorio de Programacion\\MDS7202-1-Primavera-2023\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\reshape.py:186\u001b[0m, in \u001b[0;36m_Unstacker._make_selectors\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m selector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msorted_labels[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m+\u001b[39m stride \u001b[39m*\u001b[39m comp_index \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlift\n\u001b[0;32m    185\u001b[0m mask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(np\u001b[39m.\u001b[39mprod(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfull_shape), dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m--> 186\u001b[0m mask\u001b[39m.\u001b[39;49mput(selector, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    188\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39msum() \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex):\n\u001b[0;32m    189\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mIndex contains duplicate entries, cannot reshape\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 972906993 is out of bounds for axis 0 with size 972842640"
     ]
    }
   ],
   "source": [
    "dataset.plot_vars()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Caracterizar datos de Olimpiadas (2.0 puntos)\n",
    "\n",
    "A partir de la clase que hemos desarrollado previamente, procederemos a realizar un an√°lisis exhaustivo de los datos proporcionados en el enunciado. Este an√°lisis se presentar√° en forma de un informe contenido en el mismo Jupyter Notebook y abordar√° los siguientes puntos:\n",
    "\n",
    "1. Introducci√≥n\n",
    "    - Se proporcionar√° una breve descripci√≥n del problema que estamos abordando y se explicar√° la metodolog√≠a que se seguir√°.\n",
    "\n",
    "Elaborar una breve introducci√≥n con todo lo necesario para entender qu√© realizar√°n durante su proyecto. La idea es que describan de manera formal el proyecto con sus propias palabras y logren describir algunos aspectos b√°sicos tanto del dataset como del an√°lisis a realizar sobre los datos.\n",
    "\n",
    "Por lo anterior, en esta secci√≥n ustedes deber√°n ser capaces de:\n",
    "\n",
    "- Describir la tarea asociada al dataset.\n",
    "- Describir brevemente los datos de entrada que les provee el problema.\n",
    "- Plantear hip√≥tesis de c√≥mo podr√≠an abordar el problema.\n",
    "\n",
    "2. An√°lisis del EDA (An√°lisis Exploratorio de Datos)\n",
    "    - Se discutir√°n las observaciones y conclusiones obtenidas acerca de los datos proporcionados. A lo largo de su respuesta, debe responder preguntas como:\n",
    "        - ¬øComo se comportan las variables num√©ricas? ¬øy las categ√≥ricas?\n",
    "        - ¬øExisten valores nulos en el dataset? ¬øEn qu√© columnas? ¬øCuantos?\n",
    "        - ¬øCu√°les son las categor√≠as y frecuencias de las variables categ√≥ricas?\n",
    "        - ¬øExisten datos duplicados en el conjunto?\n",
    "        - ¬øExisten relaciones o patrones visuales entre las variables?\n",
    "        - ¬øExisten anomal√≠as notables o preocupantes en los datos?\n",
    "3. Creaci√≥n de Clusters y Anomal√≠as\n",
    "    - Se justificar√° la elecci√≥n de los algoritmos a utilizar y sus hiperpar√°metros. En el caso de clustering, justifique adem√°s el n√∫mero de clusters.\n",
    "    \n",
    "4. An√°lisis de Resultados\n",
    "    - Se examinar√°n los resultados obtenidos a partir de los cl√∫sters y anomal√≠as generadas. ¬øSe logra una separaci√≥n efectiva de los datos? Entregue una interpretaci√≥n de lo que representa cada cl√∫ster y anomal√≠a.\n",
    "5. Conclusi√≥n\n",
    "    - Se resumir√°n las principales conclusiones del an√°lisis y se destacar√°n las implicaciones pr√°cticas de los resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
